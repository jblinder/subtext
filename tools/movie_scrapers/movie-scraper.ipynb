{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Panther\n",
      "{'title': 'Black Panther', 'image': 'https://ia.media-imdb.com/images/M/MV5BMTg1MTY2MjYzNV5BMl5BanBnXkFtZTgwMTc4NTMwNDI@._V1_UY222_CR0,0,150,222_AL.jpg', 'distributor': ' Buena Vista', 'release_date': ' February 16, 2018', 'genre': ' Action / Adventure', 'duration': ' 2 hrs. 20 min.', 'rating': ' PG-13', 'budget': ' N/A', 'gross_domestic': '$674,768,555', 'gross_foreign': '$640,398,043'}\n",
      "Star Wars: The Last Jedi\n",
      "{'title': 'Star Wars: The Last Jedi', 'image': 'https://ia.media-imdb.com/images/M/MV5BMjQ1MzcxNjg4N15BMl5BanBnXkFtZTgwNzgwMjY4MzI@._V1_UY222_CR0,0,150,222_AL.jpg', 'distributor': ' Buena Vista', 'release_date': ' December 15, 2017', 'genre': ' Sci-Fi Fantasy', 'duration': ' 2 hrs. 31 min.', 'rating': ' PG-13', 'budget': ' N/A', 'gross_domestic': '$620,179,216', 'gross_foreign': '$712,525,070'}\n",
      "Rogue One\n",
      "{'title': 'Rogue One', 'image': 'https://ia.media-imdb.com/images/M/MV5BMjEwMzMxODIzOV5BMl5BanBnXkFtZTgwNzg3OTAzMDI@._V1_UY222_CR0,0,150,222_AL.jpg', 'distributor': ' Buena Vista', 'release_date': ' December 16, 2016', 'genre': ' Sci-Fi Adventure', 'duration': ' 2 hrs. 13 min.', 'rating': ' PG-13', 'budget': ' $200 million', 'gross_domestic': '$532,177,324', 'gross_foreign': '$523,879,949'}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa3a931f8679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilm_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfilm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_film_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mfilms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa3a931f8679>\u001b[0m in \u001b[0;36mget_film_details\u001b[0;34m(url, title)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mparse_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mparse_finances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mparse_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mparse_sub_genre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa3a931f8679>\u001b[0m in \u001b[0;36mparse_cast\u001b[0;34m(film, table)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mfilm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'director'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mfilm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cast'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# comma seperated list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    return page\n",
    "\n",
    "'''\n",
    "Parse film list\n",
    "'''\n",
    "\n",
    "def get_film_list(url):\n",
    "    page = get_page(url)\n",
    "    films_list = {}\n",
    "    \n",
    "    list_soup=BeautifulSoup(page,\"html5lib\")\n",
    "    tables=list_soup.find_all(\"table\")\n",
    "\n",
    "    tables=list_soup.find_all(\"table\")\n",
    "    rows=[row for row in tables[2].find_all('tr')]\n",
    "    rows.pop(0) #remove header\n",
    "    for i,r in enumerate(rows):\n",
    "        items = r.find_all('td')\n",
    "        link=items[-1].find('a')['href']\n",
    "        title= items[-1].find('a').text\n",
    "        films_list[title] = \"%s%s\"%(base_url,link)\n",
    "    return films_list\n",
    "\n",
    "'''\n",
    "Parse film details\n",
    "'''\n",
    "def get_film_details(url,title):\n",
    "    page = get_page(url)\n",
    "    film = {}\n",
    "    film['title'] = title\n",
    "    print(title)\n",
    "    page_soup = BeautifulSoup(page,\"html5lib\")\n",
    "    tables = page_soup.find_all(\"table\")\n",
    "    parse_image(film,page_soup)\n",
    "    parse_details(film,tables[5])\n",
    "    parse_finances(film,tables[9])\n",
    "    parse_cast(film,tables[13])\n",
    "    parse_sub_genre(film,tables[14])\n",
    "    return film\n",
    "    \n",
    "def clean_string(raw_string):\n",
    "    printable = set(string.printable)\n",
    "    clean=[s for s in raw_string if s in printable]\n",
    "    return ''.join(clean)\n",
    "\n",
    "'''Parse poster image'''\n",
    "def parse_image(film,page_soup):\n",
    "    poster_img = page_soup.find_all(\"img\")[6]['src']\n",
    "    film['image'] = poster_img\n",
    "    \n",
    "'''Parse details table'''\n",
    "def parse_details(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    rows.pop(0) # remove header\n",
    "    prop_map = {\"Distributor\":\"distributor\", \"Release Date\": \"release_date\",\"Genre\":\"genre\",\"Runtime\":\"duration\",\"MPAA Rating\":\"rating\",\"Production Budget\":\"budget\"}\n",
    "    for row in rows:\n",
    "        # each row will have a few cells: (td~ cell tag)\n",
    "        items=row.find_all('td')\n",
    "        [parse_details_row(item,film,prop_map) for item in items]\n",
    "\n",
    "'''Parse dtails table rows'''\n",
    "def parse_details_row(row,film,prop_map):\n",
    "    data = row.text.split(':')\n",
    "    text = data[1]\n",
    "    prop = prop_map[data[0]]\n",
    "    film[prop] = text\n",
    "    \n",
    "'''Parse finance table'''\n",
    "def parse_finances(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    prop_map = {0:\"gross_domestic\",1:\"gross_foreign\"}\n",
    "    for i,row in enumerate(rows):\n",
    "    # prevent out of index error on irregular cell\n",
    "        if i < len(rows)-2:\n",
    "            items=row.find_all('td')\n",
    "            film[prop_map[i]] = clean_string(items[1].text)\n",
    "\n",
    "'''Parse cast table'''\n",
    "def parse_cast(film,table):\n",
    "    print(film)\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    film['director'] = rows[0].text.split(':')[1]\n",
    "    cast = [row.text for row in rows[1].find_all('a')]\n",
    "    cast.pop(0)\n",
    "    film['cast'] = \", \".join(cast) # comma seperated list\n",
    "\n",
    "'''Parse genre table'''\n",
    "def parse_sub_genre(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    rows.pop(0) # remove header\n",
    "    sub_genres = []\n",
    "    for row in rows:\n",
    "        g = row.find('a').text\n",
    "        sub_genres.append(g)\n",
    "    sg = clean_string(', '.join(sub_genres)) # comma seperated list\n",
    "    film['sub_genres'] = sg\n",
    "\n",
    "    \n",
    "base_url = 'http://www.boxofficemojo.com/'\n",
    "url = 'http://www.boxofficemojo.com/yearly/'\n",
    "\n",
    "\n",
    "#list_soup=BeautifulSoup(page,\"html5lib\")\n",
    "\n",
    "\n",
    "'''Get film list by metric'''\n",
    "film_list = get_film_list(url)\n",
    "# testing\n",
    "# url = 'http://www.boxofficemojo.com//movies/?id=marvel2017b.htm'\n",
    "films = []\n",
    "for film, url in film_list.items():\n",
    "    title = film\n",
    "    film = get_film_details(url,title)\n",
    "    films.append(film)\n",
    "    time.sleep(5)\n",
    "films\n",
    "\n",
    "keys = films[0].keys()\n",
    "with open('mojo_films.csv', 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(films)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Panther\n",
      "Star Wars: The Last Jedi\n",
      "Rogue One\n",
      "Star Wars: The Force Awakens\n",
      "American Sniper\n",
      "Catching Fire\n",
      "The Avengers\n",
      "Harry Potter / Deathly Hallows (P2)\n",
      "Toy Story 3\n",
      "Avatar\n",
      "The Dark Knight\n",
      "Spider-Man 3\n",
      "Dead Man's Chest\n",
      "Revenge of the Sith\n",
      "Shrek 2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    return page\n",
    "\n",
    "'''\n",
    "Parse film list\n",
    "'''\n",
    "\n",
    "def get_film_list(url):\n",
    "    page = get_page(url)\n",
    "    films_list = {}\n",
    "    \n",
    "    list_soup=BeautifulSoup(page,\"html5lib\")\n",
    "    tables=list_soup.find_all(\"table\")\n",
    "    \n",
    "    tables=list_soup.find_all(\"table\")\n",
    "    rows=[row for row in tables[2].find_all('tr')]\n",
    "    rows.pop(0) #remove header\n",
    "    for i,r in enumerate(rows):\n",
    "        items = r.find_all('td')\n",
    "        link=items[-1].find('a')['href']\n",
    "        title= items[-1].find('a').text\n",
    "        films_list[title] = \"%s%s\"%(base_url,link)\n",
    "    return films_list\n",
    "\n",
    "'''\n",
    "Parse film details\n",
    "'''\n",
    "def get_film_details(url,title):\n",
    "    page = get_page(url)\n",
    "    film = {}\n",
    "    film['title'] = title\n",
    "\n",
    "    page_soup = BeautifulSoup(page,\"html5lib\")\n",
    "    cast_table = get_table_values(page_soup,'The Players')\n",
    "    sub_genre_table = get_table_values(page_soup,'Genres')\n",
    "    \n",
    "    tables = page_soup.find_all(\"table\")\n",
    "    parse_image(film,page_soup)\n",
    "    parse_details(film,tables[5])\n",
    "    parse_finances2(film,page_soup)\n",
    "    if cast_table is not None:\n",
    "        parse_cast(film,cast_table,page_soup)\n",
    "    if sub_genre_table is not None:\n",
    "        parse_sub_genre(film,sub_genre_table)\n",
    "    return film\n",
    "    \n",
    "def clean_string(raw_string):\n",
    "    printable = set(string.printable)\n",
    "    clean=[s for s in raw_string if s in printable]\n",
    "    return ''.join(clean)\n",
    "\n",
    "'''Parse poster image'''\n",
    "def parse_image(film,page_soup):\n",
    "    poster_img = page_soup.find_all(\"img\")[6]['src']\n",
    "    film['image'] = poster_img\n",
    "    \n",
    "'''Parse details table'''\n",
    "def parse_details(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    rows.pop(0) # remove header\n",
    "    prop_map = {\"Distributor\":\"distributor\", \"Release Date\": \"release_date\",\"Genre\":\"genre\",\"Runtime\":\"duration\",\"MPAA Rating\":\"rating\",\"Production Budget\":\"budget\"}\n",
    "    for row in rows:\n",
    "        # each row will have a few cells: (td~ cell tag)\n",
    "        items=row.find_all('td')\n",
    "        [parse_details_row(item,film,prop_map) for item in items]\n",
    "\n",
    "'''Parse dtails table rows'''\n",
    "def parse_details_row(row,film,prop_map):\n",
    "    data = row.text.split(':')\n",
    "    text = data[1]\n",
    "    prop = prop_map[data[0]]\n",
    "    film[prop] = text\n",
    "    \n",
    "'''Parse finance table'''\n",
    "def parse_finances(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    prop_map = {0:\"gross_domestic\",1:\"gross_foreign\"}\n",
    "    for i,row in enumerate(rows):\n",
    "    # prevent out of index error on irregular cell\n",
    "        if i < len(rows)-2:\n",
    "            items=row.find_all('td')\n",
    "            film[prop_map[i]] = clean_string(items[1].text)\n",
    "            \n",
    "def parse_finances2(film,page_soup):\n",
    "    film['gross_domestic'] = get_movie_value(page_soup,'Domestic')\n",
    "    film['gross_foreign'] = get_movie_value(page_soup,'Foreign')\n",
    "    film['gross_worldwide'] = get_movie_value(page_soup,'Worldwide')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "'''Parse cast table'''\n",
    "def parse_cast(film,table,page_soup):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    #print(rows)\n",
    "\n",
    "    film['director'] = rows[0].text.split(':')[1]\n",
    "    cast = [row.text for row in rows[1].find_all('a')]\n",
    "    cast.pop(0)\n",
    "    film['cast'] = \", \".join(cast) # comma seperated list\n",
    "\n",
    "'''Parse genre table'''\n",
    "def parse_sub_genre(film,table):\n",
    "    rows=[row for row in table.find_all('tr')]\n",
    "    rows.pop(0) # remove header\n",
    "    sub_genres = []\n",
    "    for row in rows:\n",
    "        g = row.find('a').text\n",
    "        sub_genres.append(g)\n",
    "    sg = clean_string(', '.join(sub_genres)) # comma seperated list\n",
    "    film['sub_genres'] = sg\n",
    "\n",
    "    \n",
    "base_url = 'http://www.boxofficemojo.com/'\n",
    "url = 'http://www.boxofficemojo.com/yearly/'\n",
    "\n",
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_table_values(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find('div',text=re.compile(field_name))\n",
    "    if obj == None:\n",
    "        return None\n",
    "    table = obj.findNext('table')\n",
    "    return table\n",
    "\n",
    "\n",
    "'''Get film list by metric'''\n",
    "film_list = get_film_list(url)\n",
    "\n",
    "url = 'http://www.boxofficemojo.com//movies/?id=marvel2017b.htm'\n",
    "films = []\n",
    "\n",
    "for film,url in film_list.items():\n",
    "    print(film)\n",
    "    title = film\n",
    "    film = get_film_details(url,title)\n",
    "    films.append(film)\n",
    "    #time.sleep(1)\n",
    "\n",
    "keys = films[0].keys()\n",
    "with open('mojo_films.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(films)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
